---
title: "Analyzing effective probes data"
author: "Josef Klafka and Allyson Ettinger"
date: "7/29/2019"
output: html_document
---

```{r setup, include=FALSE}
require(tidyverse)
require(here)
require(tidyboot)

knitr::opts_chunk$set(echo = TRUE)
```

```{r read in bootstraps and plot}
targeted_tasks <- read_csv(here("results/acl/base_tasks.csv"))
distance_tasks <- read_csv(here("results/acl/distance_tasks.csv"))
wc_tasks <- read_csv(here("results/acl/word_identity.csv"))

Task_Labels <- tibble(position = c(12, 27, 42),
                          length = c(15, 30, 45),
                          gram = c("unigram", "unigram", "unigram"),
                          mean= c(4, 4, 4))

# 

targeted_tasks %>%
  mutate(Encoder = factor(Encoder, levels = c("GLoVe", "GPT", "BERT", "ELMo")), 
         Task = factor(Task, 
                       levels = c("number", "gender", "animacy", "tense", "dynamic", "causative")),
         `Probed Word` = as_factor(`Probed Word`), 
         Task_Label = ifelse(Encoder == "GLoVe" & `Probed Word` == "the_1", 
                             as.character(Task), "")) %>%
  filter(Classifier == "1024", Target == "verb") %>%
  ggplot(aes(x = `Probed Word`)) + 
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = Encoder), alpha = 1, 
                  position =  position_dodge2(width = 0.25, padding = .75)) + 
    geom_col(aes(y = Accuracy, fill = Encoder, color = Encoder), 
                      alpha = .6, position = position_dodge2(width = .75)) + 
    coord_cartesian(ylim = c(25, 100)) + 
    scale_y_continuous(breaks = c(25, 50, 75, 100)) + 
    theme_bw() + 
    scale_fill_grey() + 
    scale_color_manual(values = c("#696969", "#a9a9a9", "#696969", "#a9a9a9")) + 
    geom_text(aes(x = `Probed Word`, y = Accuracy, label = Task_Label, group = Task), 
              position = position_dodge(width = 0.50),
              size = 3,
              vjust = -0.5,
              hjust = 2.5,
              angle = -45)
    # geom_text(data = Task_Labels, aes(x = ))
    # geom_text(aes(y = Accuracy, label = Task_Label), size = 3, position = position_dodge(1),
              # angle = 45, vjust = 0)

wc_tasks %>%
  mutate(Encoder = factor(Encoder, levels = c("GLoVe", "GPT", "BERT", "ELMo")), 
         `Probed Word` = as_factor(`Probed Word`)) %>%
  filter(Classifier == "1024", Task == "subject") %>%
  ggplot(aes(x = `Probed Word`)) + 
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = Encoder), alpha = 1, 
                  position =  position_dodge2(width = 0.25, padding = .75)) + 
    geom_col(aes(y = Accuracy, fill = Encoder, color = Encoder), 
                      alpha = .6, position = position_dodge2(width = .75)) + 
    scale_y_continuous(breaks = c(25, 50, 75, 100)) + 
    theme_bw() + 
    scale_fill_grey() + 
    scale_color_manual(values = c("#696969", "#a9a9a9", "#696969", "#a9a9a9"))
```

## How we got the bootstraps

Targeted (or distance) tasks read-in, bootstrap and plotting 
```{r read in results}
## run50: get variance and plot error bars
read_run50 <- function(task) {
  
  read_csv(here(paste0("results/run50/", task, ".csv")), 
               col_names = c("Embedder", "Classifier", "Word", "Score")) %>%
    mutate(Word = as.factor(Word),
           Classifier = as.factor(Classifier), 
           Embedder = as.factor(Embedder),
           Task = task)
}

tasks <- c("subject_number", "subject_gender", "subject_animacy",
           "object_number", "object_gender", "object_animacy",
           "verb_tense", "verb_dynamic", "verb_causative")
run50 <- map_dfr(tasks, ~read_run50(.))
```

```{r bootstrap}
## for targeted and distance tasks
## read in results, filter to results where the classifier didn't get stuck in a local minimum
run50_boot <- run50 %>%
  filter(Score > 60 | Embedder == "glove" |
           (Task %in% c("object_number", "object_gender", "object_animacy") #for objects
              & Embedder == "gpt") |
           (Task %in% c("subject_number", "subject_gender", "subject_animacy") #for subjects
              & Embedder == "gpt" & Word == 0) |
           (Task %in% c("verb_tense", "verb_dynamic", "verb_causative")
              & Embedder == "gpt" & Word %in% c(0, 1))) %>% #for verbs
  group_by(Task, Embedder, Classifier, Word) %>%
  tidyboot_mean(Score) %>%
  ungroup() 

results <- run50_boot %>%
  mutate(Word = recode(Word, 
                       `0` = "the_1", `1` = "lawyers", 
                       `2` = "questioned", `3` = "the_2", `4`= "judge"), 
         Embedder = recode(Embedder, 
                           "bert" = "BERT", "elmo" = "ELMo", "glove" = "GLoVe", "gpt" = "GPT"),
         Target = str_extract(Task, "[a-z]+"),
         Task = str_extract(Task, "[a-z]+$"), 
         Task = as_factor(Task),
         Embedder = fct_relevel(Embedder, "GLoVe", "GPT", "BERT", "ELMo")) %>%
  rename(Encoder = Embedder, Accuracy = empirical_stat) 
  # bind_rows(targeted_tasks) %>%
  # write_csv(here("results/run50/bootstraps_all_tasks.csv"))

results %>%
  mutate(Encoder = factor(Encoder, levels = c("GLoVe", "GPT", "BERT", "ELMo")), 
         Word = as_factor(Word)) %>%
  filter(Classifier == "1024", Target == "subject") %>%
  ggplot(aes(x = Word)) + 
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = Encoder), alpha = 1, 
                  position =  position_dodge2(width = 0.25, padding = .75)) + 
    geom_col(aes(y = Accuracy, fill = Encoder, color = Encoder), 
                      alpha = .6, position = position_dodge2(width = .75)) + 
    coord_cartesian(ylim = c(25, 100)) + 
    scale_y_continuous(breaks = c(25, 50, 75, 100)) + 
    theme_bw() + 
    scale_fill_grey() + 
    scale_color_manual(values = c("#696969", "#a9a9a9", "#696969", "#a9a9a9"))
```

Word content tasks read-in, bootstrap and plotting
```{r read in word content results}
## run50: get variance and plot error bars
read_run50 <- function(task) {
  
  read_csv(here(paste0("results/word_content/run50/", task, ".csv")), 
               col_names = c("Embedder", "Classifier", "Word", "Score")) %>%
    mutate(Word = as.factor(Word),
           Classifier = as.factor(Classifier), 
           Embedder = as.factor(Embedder),
           Task = task)
}

tasks <- c("subject", "object", "verb")
run50 <- map_dfr(tasks, ~read_run50(.))
```

```{r word content}
## for word content tasks
run50_boot <- run50 %>%
  filter(Embedder == "glove") %>%
  # filter(Score > 5 | Embedder == "glove" | (Embedder == "gpt" & Word == 0)) %>% 
  group_by(Task, Embedder, Classifier, Word) %>%
  tidyboot_mean(Score) %>%
  rename(Score = empirical_stat) %>%
  mutate(Word = recode(Word, 
                       `0` = "the_1", `1` = "lawyers", 
                       `2` = "questioned", `3` = "the_2", `4`= "judge"))

wc_tasks %>%
  bind_rows(run50_boot) %>%
  mutate(Word = recode(Word, 
                       `0` = "the_1", `1` = "lawyers", 
                       `2` = "questioned", `3` = "the_2", `4`= "judge"), 
         Embedder = recode(Embedder, 
                           "bert" = "BERT", "elmo" = "ELMo", "glove" = "GLoVe", "gpt" = "GPT"),
         Embedder = fct_relevel(Embedder, "GLoVe", "GPT", "BERT", "ELMo")) %>%
  rename(Encoder = Embedder, Accuracy = Score) 

wrun50_boot %>%
  filter(Classifier == "1024", 
         Task == "subject") %>%
  ggplot(aes(x = Word, fill = Embedder)) + 
    geom_col(aes(y = Score), alpha = .6, 
             position = position_dodge2(width = .75)) + 
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, group = Embedder), alpha = 1, 
                  position =  position_dodge2(width = 0.25, padding = .75)) + 
    theme_bw() + 
    scale_fill_viridis(discrete = T, option = "B") +
    ggtitle("Word content subject probing task results")
```